{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark_utils import PyTorchSparkDataset\n",
    "from matplotlib import pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# We are using BETA APIs, so we deactivate the associated warning, thereby acknowledging that\n",
    "# some APIs may slightly change in the future\n",
    "torchvision.disable_beta_transforms_warning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Dataset\n",
    "\n",
    "By default, the output structure of the dataset is not compatible with the models or the transforms (https://pytorch.org/vision/master/transforms.html#v1-or-v2-which-one-should-i-use). To overcome that, we wrap a `PyTorchSparkDataset` in`PyTorchSparkDatasetV2`.\n",
    "\n",
    "In the code below, we are wrapping images and bounding boxes `torchvision.TVTensor classes` so that we will be able to apply torchvision built-in transformations for the given object detection and segmentation task. Namely, image tensors will be wrapped by `torchvision.tv_tensors.Image` and bounding boxes into `torchvision.tv_tensors.BoundingBoxes`. Our dataset now returns a target which is dict where the values are `TVTensors` (all are `torch.Tensor` subclasses).\n",
    "\n",
    "We also make the dataset compliant with COCO requirements so that it will work for both training and evaluation codes from the COCO reference script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap a PyTorchSparkDataset dataset for usage with torchvision.transforms.v2\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "\n",
    "class PyTorchSparkDatasetV2(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, class_map, split='train', root_dir='', transform=None, detection=True):\n",
    "        super().__init__()\n",
    "        self.dataset = PyTorchSparkDataset(class_map, split=split, root_dir=root_dir, transform=transform, detection=detection)\n",
    "        self.detection = detection\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label, bbox = self.dataset[idx]\n",
    "\n",
    "        image = torchvision.tv_tensors.Image(image)\n",
    "\n",
    "        \n",
    "        bbox = torchvision.tv_tensors.BoundingBoxes(bbox,\n",
    "                                                    format=torchvision.tv_tensors.BoundingBoxFormat.XYXY, \n",
    "                                                    canvas_size=F.get_size(image))\n",
    "        label = torch.tensor([label])\n",
    "        area = (bbox[:, 3] - bbox[:, 1]) * (bbox[:, 2] - bbox[:, 0])\n",
    "        iscrowd = torch.zeros((1,), dtype=torch.int64)\n",
    "        image_id = idx\n",
    "\n",
    "        target = {\n",
    "            'boxes': bbox, \n",
    "            'labels': label,\n",
    "            'area': area, \n",
    "            'iscrowd': iscrowd\n",
    "            'image_id': image_id, \n",
    "        }\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms\n",
    "\n",
    "Letâ€™s now define our pre-processing transforms. All the transforms know how to handle images, bouding boxes and masks when relevant.\n",
    "\n",
    "Transforms are typically passed as the transforms parameter of the dataset so that they can leverage multi-processing from the `torch.utils.data.DataLoader`.\n",
    "\n",
    "- http://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_e2e.html#transforms-v2-end-to-end-object-detection-segmentation-example\n",
    "- https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as T\n",
    "from torchvision import models, datasets, tv_tensors\n",
    "\n",
    "# Define the transforms to be applied to the data.\n",
    "def get_transform(is_train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToImage())\n",
    "\n",
    "    # TODO: Add your own transformations for the train set here.\n",
    "    \n",
    "    # if is_train:\n",
    "        # transforms.append(T.RandomPhotometricDistort(p = 0.5))\n",
    "        # transforms.append(T.RandomZoomOut(fill={tv_tensors.Image: (123, 117, 104), \"others\": 0}))\n",
    "        # transforms.append(T.RandomIoUCrop())\n",
    "        # transforms.append(T.RandomHorizontalFlip(p = 0.5))\n",
    "        # transforms.append(T.SanitizeBoundingBoxes())\n",
    "\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    \n",
    "    return T.Compose(transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(is_train, class_map, data_path):\n",
    "\n",
    "    split = \"train\" if is_train else \"validation\"\n",
    "\n",
    "    # We use the PyTorchSparkDatasetV2 class defined above.\n",
    "    dataset = PyTorchSparkDatasetV2(class_map=class_map, \n",
    "                                    split=split, \n",
    "                                    root_dir=data_path, \n",
    "                                    transform=get_transform(is_train))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 30\n",
      "Number of validation samples: 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up the path to a local copy of the SPARK dataset, labels csv files should be in the same directory.\n",
    "# The image sets should be in /data/train, /data/validation and /data/test.\n",
    "data_path = './data/'\n",
    "\n",
    "# Define the class map, this is a dictionary that maps the class names to integer labels.\n",
    "class_map = {'proba_2':0, 'cheops':1, 'debris':2, 'double_star':3, 'earth_observation_sat_1':4, 'lisa_pathfinder':5,\n",
    "                        'proba_3_csc' :6, 'proba_3_ocs':7, 'smart_1':8, 'soho':9, 'xmm_newton':10}\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = len(class_map)\n",
    "\n",
    "# # Define the datasets for training and validation.\n",
    "dataset = get_dataset(is_train=True, class_map=class_map, data_path=data_path)\n",
    "dataset_valid = get_dataset(is_train=False, class_map=class_map, data_path=data_path)\n",
    "\n",
    "print(f\"Number of training samples: {len(dataset)}\")\n",
    "print(f\"Number of validation samples: {len(dataset_valid)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image type: <class 'torchvision.tv_tensors._image.Image'>\n",
      "Image shape: torch.Size([3, 1024, 1024])\n",
      "Image dtype: torch.float32\n",
      "\n",
      "Target type: <class 'dict'>\n",
      "Target keys:  ['boxes', 'labels', 'image_id', 'area', 'iscrowd']\n",
      "\n",
      "Boxes type: <class 'torchvision.tv_tensors._bounding_boxes.BoundingBoxes'>\n",
      "Boxes shape: torch.Size([1, 4])\n",
      "\n",
      "Labels type: <class 'torch.Tensor'>\n",
      "Labels shape: torch.Size([1])\n",
      "Labels dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Check dataset format for debugging purposes\n",
    "sample = dataset[0]\n",
    "image, target = sample\n",
    "\n",
    "print(f\"Image type: {type(image)}\")\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Image dtype: {image.dtype}\")\n",
    "print()\n",
    "print(f\"Target type: {type(target)}\")\n",
    "print(\"Target keys: \", list(target.keys()))\n",
    "print()\n",
    "print(f\"Boxes type: {type(target['boxes'])}\")\n",
    "print(f\"Boxes shape: {target['boxes'].shape}\")\n",
    "print()\n",
    "print(f\"Labels type: {type(target['labels'])}\")\n",
    "print(f\"Labels shape: {target['labels'].shape}\")\n",
    "print(f\"Labels dtype: {target['labels'].dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark_utils import SPARKDataset\n",
    "\n",
    "rows, cols = 3, 4\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 15))\n",
    "\n",
    "# Note that we are using the SPARKDataset class here instead of the PyTorchSparkDatasetV2 class\n",
    "ds = SPARKDataset(class_map, root_dir=data_path,split='train')\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        ds.visualize(randint(0, len(dataset)),\n",
    "                     size=(10,10),\n",
    "                     ax=axes[i][j])\n",
    "        axes[i][j].axis('off')\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size to be used.\n",
    "batch_size = 10\n",
    "\n",
    "# Define the dataloaders for training and validation.\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda batch: tuple(zip(*batch)),\n",
    ")\n",
    "\n",
    "data_loader_valid = torch.utils.data.DataLoader(\n",
    "    dataset_valid,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    collate_fn=lambda batch: tuple(zip(*batch)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model\n",
    "\n",
    "We will be using Faster R-CNN V2. Faster R-CNN V2 is a model that predicts both bounding boxes and class scores for potential objects in the image. It works similarly to Faster R-CNN with ResNet-50 FPN backbone.\n",
    "\n",
    "We will start from a model pre-trained on COCO and finetune it for our particular classes in order to perform transfer learning.\n",
    "\n",
    "- https://pytorch.org/vision/main/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn_v2.html\n",
    "- https://pytorch.org/vision/main/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn.html\n",
    "- https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# Define the model\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # Load an instance segmentation model pre-trained on COCO\n",
    "    # TODO: Experiment with other weights such as 'COCO_V1'\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(weights=\"DEFAULT\")\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Below is the main function which performs the training and the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [0/3]  eta: 0:01:58  lr: 0.002503  loss: 1.1445 (1.1445)  loss_classifier: 1.0283 (1.0283)  loss_box_reg: 0.0250 (0.0250)  loss_objectness: 0.0867 (0.0867)  loss_rpn_box_reg: 0.0045 (0.0045)  time: 39.3634  data: 0.1602\n",
      "Epoch: [0]  [2/3]  eta: 0:00:39  lr: 0.005000  loss: 1.1445 (1.0402)  loss_classifier: 1.0283 (0.9128)  loss_box_reg: 0.0250 (0.0241)  loss_objectness: 0.0867 (0.0974)  loss_rpn_box_reg: 0.0057 (0.0059)  time: 39.3839  data: 0.1341\n",
      "Epoch: [0] Total time: 0:01:58 (39.3852 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Test:  [0/3]  eta: 0:00:35  model_time: 11.6013 (11.6013)  evaluator_time: 0.0089 (0.0089)  time: 11.7245  data: 0.1142\n",
      "Test:  [2/3]  eta: 0:00:11  model_time: 11.6013 (11.5169)  evaluator_time: 0.0140 (0.0133)  time: 11.6403  data: 0.1072\n",
      "Test: Total time: 0:00:34 (11.6405 s / it)\n",
      "Averaged stats: model_time: 11.6013 (11.5169)  evaluator_time: 0.0140 (0.0133)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      "Epoch: [1]  [0/3]  eta: 0:01:59  lr: 0.005000  loss: 0.3123 (0.3123)  loss_classifier: 0.1835 (0.1835)  loss_box_reg: 0.0391 (0.0391)  loss_objectness: 0.0840 (0.0840)  loss_rpn_box_reg: 0.0057 (0.0057)  time: 39.9543  data: 0.1119\n",
      "Epoch: [1]  [2/3]  eta: 0:00:39  lr: 0.005000  loss: 0.1949 (0.2228)  loss_classifier: 0.0724 (0.1004)  loss_box_reg: 0.0391 (0.0302)  loss_objectness: 0.0840 (0.0865)  loss_rpn_box_reg: 0.0057 (0.0057)  time: 39.7293  data: 0.1208\n",
      "Epoch: [1] Total time: 0:01:59 (39.7307 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Test:  [0/3]  eta: 0:00:35  model_time: 11.8369 (11.8369)  evaluator_time: 0.0013 (0.0013)  time: 11.9528  data: 0.1146\n",
      "Test:  [2/3]  eta: 0:00:11  model_time: 11.6446 (11.6401)  evaluator_time: 0.0011 (0.0011)  time: 11.7541  data: 0.1116\n",
      "Test: Total time: 0:00:35 (11.7543 s / it)\n",
      "Averaged stats: model_time: 11.6446 (11.6401)  evaluator_time: 0.0011 (0.0011)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Epoch: [2]  [0/3]  eta: 0:01:55  lr: 0.005000  loss: 0.2201 (0.2201)  loss_classifier: 0.1012 (0.1012)  loss_box_reg: 0.0543 (0.0543)  loss_objectness: 0.0604 (0.0604)  loss_rpn_box_reg: 0.0043 (0.0043)  time: 38.3913  data: 0.1174\n",
      "Epoch: [2]  [2/3]  eta: 0:00:39  lr: 0.005000  loss: 0.2201 (0.2032)  loss_classifier: 0.1012 (0.0957)  loss_box_reg: 0.0485 (0.0401)  loss_objectness: 0.0604 (0.0620)  loss_rpn_box_reg: 0.0050 (0.0054)  time: 39.2816  data: 0.1216\n",
      "Epoch: [2] Total time: 0:01:57 (39.2826 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Test:  [0/3]  eta: 0:00:36  model_time: 12.1428 (12.1428)  evaluator_time: 0.0014 (0.0014)  time: 12.2639  data: 0.1196\n",
      "Test:  [2/3]  eta: 0:00:12  model_time: 11.8641 (11.9491)  evaluator_time: 0.0012 (0.0013)  time: 12.0645  data: 0.1129\n",
      "Test: Total time: 0:00:36 (12.0647 s / it)\n",
      "Averaged stats: model_time: 11.8641 (11.9491)  evaluator_time: 0.0012 (0.0013)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Epoch: [3]  [0/3]  eta: 0:02:00  lr: 0.000500  loss: 0.2915 (0.2915)  loss_classifier: 0.1741 (0.1741)  loss_box_reg: 0.0675 (0.0675)  loss_objectness: 0.0449 (0.0449)  loss_rpn_box_reg: 0.0049 (0.0049)  time: 40.0241  data: 0.1179\n",
      "Epoch: [3]  [2/3]  eta: 0:00:39  lr: 0.000500  loss: 0.2251 (0.2062)  loss_classifier: 0.1094 (0.1056)  loss_box_reg: 0.0432 (0.0405)  loss_objectness: 0.0491 (0.0545)  loss_rpn_box_reg: 0.0049 (0.0056)  time: 39.7151  data: 0.1240\n",
      "Epoch: [3] Total time: 0:01:59 (39.7166 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Test:  [0/3]  eta: 0:00:37  model_time: 12.4209 (12.4209)  evaluator_time: 0.0014 (0.0014)  time: 12.5579  data: 0.1355\n",
      "Test:  [2/3]  eta: 0:00:11  model_time: 11.2542 (11.5377)  evaluator_time: 0.0011 (0.0012)  time: 11.6583  data: 0.1181\n",
      "Test: Total time: 0:00:34 (11.6585 s / it)\n",
      "Averaged stats: model_time: 11.2542 (11.5377)  evaluator_time: 0.0011 (0.0012)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Epoch: [4]  [0/3]  eta: 0:01:48  lr: 0.000500  loss: 0.2525 (0.2525)  loss_classifier: 0.1548 (0.1548)  loss_box_reg: 0.0540 (0.0540)  loss_objectness: 0.0383 (0.0383)  loss_rpn_box_reg: 0.0053 (0.0053)  time: 36.0766  data: 0.1175\n",
      "Epoch: [4]  [2/3]  eta: 0:00:37  lr: 0.000500  loss: 0.2525 (0.2370)  loss_classifier: 0.1473 (0.1382)  loss_box_reg: 0.0540 (0.0486)  loss_objectness: 0.0449 (0.0447)  loss_rpn_box_reg: 0.0053 (0.0056)  time: 37.7991  data: 0.1189\n",
      "Epoch: [4] Total time: 0:01:53 (37.8001 s / it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Test:  [0/3]  eta: 0:00:36  model_time: 12.1510 (12.1510)  evaluator_time: 0.0012 (0.0012)  time: 12.2725  data: 0.1203\n",
      "Test:  [2/3]  eta: 0:00:12  model_time: 12.1510 (12.3631)  evaluator_time: 0.0011 (0.0011)  time: 12.4776  data: 0.1119\n",
      "Test: Total time: 0:00:37 (12.4778 s / it)\n",
      "Averaged stats: model_time: 12.1510 (12.3631)  evaluator_time: 0.0011 (0.0011)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "# Train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Get the model using our helper function\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "# Move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# Construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "# And a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "# Let's train it for 5 epochs\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # Update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # Evaluate on the test dataset\n",
    "    evaluate(model, data_loader_valid, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
